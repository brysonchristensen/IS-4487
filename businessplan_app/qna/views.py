import re
from django.shortcuts import render
from django.http import HttpRequest

# This is the processed text from the business plan PDF.
# In a real application, this would be loaded from a file or database.
processed_text = """bc neuromarkets  business plan confidential draft  prepared for internal planning and prospective advisor review executive summary bc neuromarkets bcn is a quantitative research and trading firm that harnesses a multimodal decision engine technical and fundamental analysis realtime market microstructure and largescale sentiment signals from financial news and social platforms grokxreddit all unified under behavioral finance principles bcn will start as a proprietary trading operation deploying the founders capital across us equities and equity options with swing and position horizons first adding intraday strategies as infrastructure matures after establishing a verified track record bcn will expand into a hedge fund structure to manage outside capital our edge is the integration of rational signals valuation momentum microstructure and irrational dynamics crowd behavior feargreed cycles herding to anticipate trend formation and inflection the initial goal is to compound capital with controlled volatility and shallow drawdowns then scale aum under an institutional framework problem  opportunity public markets are efficient on average but persistently inefficient at the edges especially around information velocity newssocial and human behavior bias overreaction fomopanic retail tools focus on charts institutional tools often treat sentiment and behavior as peripheral the opportunity is to quantify market psychology at scale fuse it with classic quant views and execute systematically unique selling proposition usp bc neuromarkets unifies five pillars into a single engine 1 technical factors trend momentum volatility regimes market internals 2 fundamental context earnings revisions balance sheet quality macro sensitivity 3 realtime market data order flow liquidity microstructure anomalies 4 sentiment  narrative financial news  xredditgrok signals topic dispersion stance 5 behavioral finance herding overreaction loss aversion disposition effect proxies rather than stacking independent signals bcn builds interacting featureseg momentum signals conditioned on sentiment dispersion and fundamental revision breadthto predict emerging trend durability and meanreversion risk market focus  instruments instruments us equities single names  etfs and equity options definedrisk structures preferred horizons start with swing daysweeks and position weeksmonths add intraday later for liquidity harvesting and hedging universe liquid midlargecap equities and sector etfs options restricted to names with sufficient liquidity and robust chains product  technology  data  ingestion market data consolidated realtimertd equity and options quotes order book depth where available historical bars fundamentals earnings revisions quality metrics sector classifications macro calendars news  social aggregated feeds financial news apis xreddit firehose where permissible grokx semantic insights pipelines kafka streaming redis cachinglowlatency postgresparquet historical lakes feature store versioned features with data lineage to prevent leakage product  technology  modeling stack python core with scikitlearn for tabular baselines pytorch for sequenceattention models on time series and text embeddings nlp  llms topic clustering stancesentiment scoring dispersion metrics and narrative regime detection eg ai cycle rate cuts geopolitics feature architecture interactions of tafasentiment crowding and behavioral factors optionssurfaceaware signals impliedrealized spread skew backtesting purgedembargoed walkforward combinatorial crossvalidation to mitigate lookaheadleakage execution smartrouted marketable limits and twapvwap slicing for size options routes with definedrisk priority monitoring latency fill quality slippage vs arrival model drift and risk breaches with realtime alerts product  technology  dashboards  ops internal console live signals portfolio greeks exposure sentiment indices narrative maps event calendar risk flags analytics pl attribution by factor sentiment bucket and crowding cohort regime heatmaps risk management v10 objectives minimize depthfrequency of drawdowns while preserving upside convexity portfolio limits max gross 200 max net 60 singlename risk  20 of equity deltaequiv sector cap  20 of equity liquidity rules to avoid crowding vol targeting aim 10 annualized if realized 12 for 5 days autoderisk 20 gross drawdown brakes 6 cut gross 25 10 cut 50 halt new swingposition 15 capital preservation mode strategy buckets position 075125 risk per name 25atr or structure stop takeprofittrailing logic swing 050085 risk 18atr stops 10day time stop if thesis fails intraday later 010025 risk 125 daily loss stop flat by close options controls net delta near neutral unless intentional caps on net vegagamma definedrisk spreads favored earnings trades strictly definedrisk with 04 equity at risk per name eventrisk halts earnings no new nondefinedrisk positions from t2 to t reduce delta 50 into report macro cpinfpfomc t1 cut gross 25 cap net 20 intraday flat 5 min before to 10 min after prints kill switches  ops hard stops honored daily kill at 20 daytodate flatten on data integrity issues versioned model governance and production change controls gotomarket  growth path phase i  proprietary trading months 012 build pipelines feature store and v1 models trade swingposition strategies in live capital with conservative sizing establish measured auditable track record monthly letters factor attribution risk stats publish nonpromotional research notes behavioral  sentiment insights to build credibility phase ii  institutionalization months 1224 formalize compliance and audit processes trade surveillance bestex valuation thirdparty performance verification secure legal counsel for fund formation delaware lpgp or comparable seedanchor conversations with hnwfocta allocators based on verified live results phase iii  hedge fund launch months 1830 launch a limited partnership managementperformance fee model scale infrastructure kubernetes ha data feeds dr sites add intraday strategies and capitalefficient option overlays for riskmanaged alpha monetization  economics phase i pl from proprietary trading reinvest to expand data compute and team phase iiiii hedge fund fee structure eg 15  1520 potentially with founderfriendly terms for early anchors optional secondary revenue streams research notes or anonymized factor data used sparingly to avoid alpha leakage costs  priorities datafeeds 30120k depending on vendors and entitlements computestorageinfra 1236k legalcomplianceaccounting 1030k heavier near fund launch talent lean core  contractors 120250k total operating range 200450k scalable with needs competitive landscape retail tools emphasize charting and basic sentiment institutional platforms integrate marketfundamental data but often treat social sentiment and behavior as noise bc neuromarkets competes by tightly coupling sentiment and behavior to executionrelevant signals eg when to trust momentum vs fade it based on narrative dispersion and crowding defensibility increases with proprietary labels feature engineering and live trade data that refine models in ways competitors cannot easily replicate defensibility  moat proprietary data exhaust labels feature interactions and execution outcomes improve models through continual learning behavioral layer purposebuilt indices eg sentiment dispersion conviction skew retailinstitutional divergence that are hard to clone process moat governance slippage control eventrisk discipline brand  credibility transparent letters research discipline and clean ops history compliance  legal phase i trade only firm capital educational tone in any public content maintain trade logs bestex analysis modelversion controls and archival of research decisions phase iiiii engage counsel to structure fund delaware lpgp or equivalent draft lpappm establish riaexempt reporting adviser status as applicable implement amlkyc and custodial relationships and formalize cybersecurity and bcpdr plans team  roles initial founder  cio strategy design portfolio risk research direction quant researcher contracttohire feature engineering backtests nlpllm pipelines dataml engineer pipelines feature store cicd monitoring and model ops parttime opscompliance outsourced initially trade surveillance booksrecords brokerexecution review milestones  12month roadmap q1 months 03 stand up data ingestion and feature store sentiment  narrative indices v1 backtest two core strategies implement risk framework v10 and papertrade 68 weeks q2 months 46 live trading with conservative sizing weekly risk reviews launch internal dashboard signals risk events publish first research note kpi targets for execution and uptime q3 months 79 expand universe add options overlays ensemble v2 with macroregime awareness thirdparty performance verification ddq draft q4 months 1012 intraday alpha prototypes legal structuring discussions aggregate 912 months of auditable performance with attribution kpis return quality annualized return sharpe 12 target year 1 sortino calmar risk max drawdown 10 target realized vol vs 10 hit ratio winloss asymmetry execution slippage vs arrivalvwap fill rate ordertofill latency signal health ic feature drift stats regime stability process uptime alert response time  trades within risk policy audit exceptions  0 financial outline year 1 costs rough datafeeds equitiesoptionsnewssocial 30120k computestorageinfra 1236k brokerageexchange fees variable legalcomplianceaccounting 1030k talent 120250k total 200450k scalable capital use prioritize data quality monitoring and risk systems reinvest trading profit into data breadth and engineering capacity branding  communications name bc neuromarkets modern professional personal design dark sophisticated interface minimalist logo with bc monogram  neuralmarketwave motif voice evidencedriven and measured emphasize process risk control and research discipline risks  mitigations model overfit  regime shifts purged walkforward stress tests 2008201120202022 ensemble diversity data quality  latency redundant vendors heartbeat monitoring failover playbooks crowding  capacity favor liquid names crowding indicators gradual size ramps compliance  ops early documentation external counsel conservative communications talent  scale contractor model early convert to core hires as pl supports conclusion  immediate next steps bc neuromarkets is built to exploit a structural gap markets price fundamentals and trends but often misprice human behavior by encoding behavioral finance directly into the modeling and execution loopand proving results first with our own capitalbcn aims to deliver repeatable riskaware returns and graduate to a hedge fund with institutional processes and partners immediate next steps 1 finalize data vendor selections and entitlements 2 stand up streaming pipelines feature store and version control for models 3 implement risk framework v10 in pretrade checks 4 complete initial backtests with purged walkforward lock deployment criteria 5 begin live trading with conservative sizing and full monitoring 6 draft monthly letter template start building verified track record 7 engage counsel on fund structure timing prepare ddq and ops documentation"""

keywords = {
    "mission": ["mission", "goal", "purpose"],
    "target market": ["target market", "customers", "audience"],
    "product/service": ["product", "service", "solution"],
    "business model": ["business model", "revenue", "pricing"],
    "team": ["team", "management"],
    "financials": ["financial", "funding", "investment"],
    "marketing": ["marketing", "sales", "strategy"]
}

def answer_query(query: str, text: str) -> str:
    query = query.lower()
    relevant_sections = []

    for section, terms in keywords.items():
        if any(term in query for term in terms):
            section_text = ""
            for term in terms:
                if term in text:
                    start_index = text.find(term)
                    if start_index != -1:
                        window_size = 500
                        start = max(0, start_index - window_size)
                        end = min(len(text), start_index + len(term) + window_size)
                        section_text += text[start:end] + "..."
            if section_text:
                relevant_sections.append(f"Information about {section}:\n{section_text}\n")

    if not relevant_sections:
        query_terms = query.split()
        matching_sentences = []
        sentences = text.split('.')
        for sentence in sentences:
            if any(term in sentence for term in query_terms):
                matching_sentences.append(sentence.strip())

        if matching_sentences:
            return "Found potential relevant sentences:\n" + "\n".join(matching_sentences[:3])

    if relevant_sections:
        return "\n".join(relevant_sections)
    else:
        return "Could not find relevant information for your query."

def index(request: HttpRequest):
    """Renders the index page."""
    return render(request, 'index.html')

def ask(request: HttpRequest):
    """Handles user queries and returns the response."""
    query = ""
    response = ""
    if request.method == 'POST':
        query = request.POST.get('query', '')
        response = answer_query(query, processed_text)

    return render(request, 'index.html', {'query': query, 'response': response})